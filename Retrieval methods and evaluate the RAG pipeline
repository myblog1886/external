from transformers import AutoTokenizer, AutoModel
import faiss
import numpy as np
import mlflow

# Sample Corpus
corpus = [
    "The quick brown fox jumps over the lazy dog.",
    "A stitch in time saves nine.",
    "An apple a day keeps the doctor away.",
    "To be or not to be, that is the question.",
    "All that glitters is not gold.",
    "A journey of a thousand miles begins with a single step.",
    "Actions speak louder than words.",
    "Beauty is in the eye of the beholder.",
    "Better late than never.",
    "Birds of a feather flock together."
]

# Encode the corpus
def encode_corpus(corpus, model_name):
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name)
    encoded_corpus = []

    for text in corpus:
        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
        outputs = model(**inputs)
        encoded_corpus.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())

    return np.vstack(encoded_corpus)

# Create FAISS index
def create_faiss_index(encoded_corpus):
    d = encoded_corpus.shape[1]
    index = faiss.IndexFlatL2(d)
    index.add(encoded_corpus)
    return index

class SentenceWindowRetrieval:
    def __init__(self, model_name, index, window_size=2):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.index = index
        self.window_size = window_size

    def encode(self, text):
        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)
        outputs = self.model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).detach().numpy()

    def retrieve(self, query, corpus, n=5):
        query_vector = self.encode(query)
        D, I = self.index.search(query_vector, n)
        retrieved_sentences = [corpus[i] for i in I[0]]

        # Implement window retrieval
        windowed_results = []
        for i in I[0]:
            start = max(0, i - self.window_size)
            end = min(len(corpus), i + self.window_size + 1)
            windowed_results.extend(corpus[start:end])

        return windowed_results

class AutoMergingRetrieval:
    def __init__(self, model_name, index, merge_threshold=0.8):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.index = index
        self.merge_threshold = merge_threshold

    def encode(self, text):
        inputs = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)
        outputs = self.model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).detach().numpy()

    def merge_sentences(self, sentences):
        merged_sentences = []
        current_chunk = sentences[0]
        for sentence in sentences[1:]:
            if self.similarity(current_chunk, sentence) > self.merge_threshold:
                current_chunk += " " + sentence
            else:
                merged_sentences.append(current_chunk)
                current_chunk = sentence
        merged_sentences.append(current_chunk)
        return merged_sentences

    def similarity(self, sentence1, sentence2):
        vec1 = self.encode(sentence1)
        vec2 = self.encode(sentence2)
        return np.dot(vec1, vec2.T) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))

    def retrieve(self, query, corpus, n=5):
        query_vector = self.encode(query)
        D, I = self.index.search(query_vector, n)
        retrieved_sentences = [corpus[i] for i in I[0]]

        # Implement auto-merging
        merged_results = self.merge_sentences(retrieved_sentences)
        return merged_results

def evaluate_rag(model_name, retriever, dataset, metrics):
    results = {"context_relevance": [], "groundedness": [], "answer_relevance": []}
    for query, expected_answer in dataset:
        retrieved_contexts = retriever.retrieve(query, corpus)
        # For simplicity, let's assume generated_answer is concatenation of retrieved contexts
        generated_answer = " ".join(retrieved_contexts)

        results["context_relevance"].append(metrics["context_relevance"](query, retrieved_contexts))
        results["groundedness"].append(metrics["groundedness"](generated_answer, retrieved_contexts))
        results["answer_relevance"].append(metrics["answer_relevance"](generated_answer, expected_answer))

    return {metric: np.mean(scores) for metric, scores in results.items()}

def track_experiment(experiment_name, run_name, params, metrics):
    mlflow.set_experiment(experiment_name)
    with mlflow.start_run(run_name=run_name):
        for key, value in params.items():
            mlflow.log_param(key, value)
        for key, value in metrics.items():
            mlflow.log_metric(key, value)

def main():
    model_name = "bert-base-uncased"
    encoded_corpus = encode_corpus(corpus, model_name)
    index = create_faiss_index(encoded_corpus)

    # Define retrieval methods
    sw_retriever = SentenceWindowRetrieval(model_name, index)
    am_retriever = AutoMergingRetrieval(model_name, index)

    # Define your evaluation dataset and metrics
    evaluation_dataset = [("What is a common phrase about prevention?", "A stitch in time saves nine."), 
                          ("What do people say about actions?", "Actions speak louder than words.")]
    evaluation_metrics = {
        "context_relevance": lambda query, contexts: len(contexts) > 0,  # Dummy metric for example
        "groundedness": lambda answer, contexts: any(context in answer for context in contexts),  # Dummy metric for example
        "answer_relevance": lambda answer, expected: answer == expected  # Dummy metric for example
    }

    # Evaluate retrievers
    sw_metrics = evaluate_rag(model_name, sw_retriever, evaluation_dataset, evaluation_metrics)
    am_metrics = evaluate_rag(model_name, am_retriever, evaluation_dataset, evaluation_metrics)

    # Track experiments
    track_experiment("RAG Experiments", "Sentence-Window Retrieval", {"method": "Sentence-Window"}, sw_metrics)
    track_experiment("RAG Experiments", "Auto-Merging Retrieval", {"method": "Auto-Merging"}, am_metrics)

if __name__ == "__main__":
    main()
